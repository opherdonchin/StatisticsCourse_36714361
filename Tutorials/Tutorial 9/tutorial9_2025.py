# -*- coding: utf-8 -*-
"""Tutorial9_2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s8yefHMezHX1sYPNJVux5EFitQptjxZf

# **Tutorial 9**

### Imports
"""

import numpy as np # arrays, array operations
import scipy.stats as stats # statistics
from google.colab import files
import matplotlib.pyplot as plt # plot graphs
import pandas as pd #dataframes
import io
import xarray as xr #multidimensional dataframes
import pymc as pm
import arviz as az
import seaborn as sns
import scipy.interpolate as interpolate

#preliz
!pip install preliz
import preliz as pz

"""### Coin Flip Example

Data
"""

trials = 100
theta_real = 0.3 # unknown value in a real experiment
data = pz.Binomial(n=1, p=theta_real).rvs(trials)
data

"""Model"""

coords = {"data": np.arange(len(data))}

with pm.Model(coords=coords) as model_1:
    thet = pm.Beta('thet', alpha=1., beta=1.)
    y = pm.Bernoulli('y', p=thet, observed=data, dims = 'data')
    idata1 = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})

az.summary(idata1)

"""WAIC and LOO on our model"""

az.waic(idata1)

print(az.loo(idata1))

"""Creating the null model"""

#choose prior
pz.maxent(pz.Beta(), 0.45, 0.55, 0.95)

with pm.Model() as model_null:
    thet_null = pm.Beta('thet_null', alpha=200, beta=200) #prior defined based on ROPE
    y_null = pm.Bernoulli('y_null', p=thet_null, observed=data) #likelihood
    idata_null = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})


# Compare LOO
az.compare({"alternative": idata1, "null": idata_null})

# Compare WAIC
az.compare({"alternative": idata1, "null": idata_null}, ic = 'waic')

"""### Bikes Example"""

bikes = pd.read_csv("https://github.com/aloctavodia/BAP3/raw/refs/heads/main/code/data/bikes.csv")

"""Linear Regression Model"""

coords = {"data": np.arange(len(bikes))}
with pm.Model(coords=coords) as model_lb:
    β0 = pm.Normal("β0", mu=0, sigma=100)
    β1 = pm.Normal("β1", mu=0, sigma=10)
    σ = pm.HalfNormal("σ", 10)
    μ = pm.Deterministic("μ", β0 + β1 * bikes.temperature, dims="data")
    y_pred = pm.Normal("y_pred", mu=μ, sigma=σ, observed=bikes.rented, dims="data")
    idata_lb = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})

"""Negative Binomial Model"""

mu_0 = 0
sigma_0 = 1
mu_1 = 0
sigma_1 = 10
sigma_alpha = 10

with pm.Model() as model_neg:
    beta0 = pm.Normal("beta0", mu=mu_0, sigma=sigma_0)
    beta1 = pm.Normal("beta1", mu=mu_1, sigma=sigma_1)
    alpha = pm.HalfNormal("alpha", sigma=sigma_alpha)
    mu = pm.Deterministic("mu", pm.math.exp(beta0 + beta1 * bikes.temperature))
    y_pred = pm.NegativeBinomial("y_pred", mu=mu, alpha=alpha, observed=bikes.rented)
    idata_neg = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})

"""LOO and WAIC"""

#LOO
az.compare({"linear": idata_lb, "negative_binomial": idata_neg})

#WAIC
az.compare({"linear": idata_lb, "negative_binomial": idata_neg}, ic = 'waic')

"""Multiple Regression"""

with pm.Model() as model_mlb:
    α = pm.Normal("α", mu=0, sigma=1)
    β0 = pm.Normal("β0", mu=0, sigma=10)
    β1 = pm.Normal("β1", mu=0, sigma=10)
    σ = pm.HalfNormal("σ", 10)
    μ = pm.Deterministic("μ", pm.math.exp(α + β0 * bikes.temperature + β1 * bikes.humidity))
    _ = pm.NegativeBinomial("y_pred", mu=μ, alpha=σ, observed=bikes.rented)

    idata_mlb = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})

#LOO
az.compare({"linear": idata_lb, "negative_binomial": idata_neg, "negative_binomial_multiple": idata_mlb})

"""### Model Averaging

Data
"""

N = 100
x = np.linspace(-3, 3, N)
y_true = 0.5 * x**2 + 2 * x + 1
y = y_true + np.random.normal(0, 2, size=N)

plt.scatter(x, y)
plt.xlabel('X')
plt.xlabel('Y')
plt.savefig('data.png')
files.download("data.png")

"""Linear Model"""

with pm.Model(coords={"data": np.arange(N)}) as linear_model:
    alpha = pm.Normal("alpha", 0, 10)
    beta = pm.Normal("beta", 0, 10)
    sigma = pm.HalfNormal("sigma", 5)

    mu = pm.Deterministic('mu', alpha + beta * x)
    y_obs = pm.Normal("y_obs", mu=mu, sigma=sigma, observed=y, dims="data")

    idata_linear = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})

pm.sample_posterior_predictive(idata_linear, model=linear_model, extend_inferencedata=True)

#plot mean
posterior = az.extract(idata_linear, num_samples=len(x))
x_plot = xr.DataArray(x)

mean_line = posterior["alpha"].mean() + posterior["beta"].mean() * x_plot

plt.scatter(x, y)
plt.plot(x_plot, mean_line, c="C1")
plt.xlabel('X', fontsize = 14)
plt.ylabel('Y', fontsize = 14)
plt.title('Linear', fontsize = 14)


plt.savefig("lines.png", bbox_inches='tight')
files.download("lines.png")

"""Quadratic"""

with pm.Model(coords={"data": np.arange(N)}) as quad_model:
    x_data = pm.MutableData("x", x)
    alpha = pm.Normal("alpha", 0, 10)
    beta1 = pm.Normal("beta1", 0, 10)
    beta2 = pm.Normal("beta2", 0, 10)
    sigma = pm.HalfNormal("sigma", 5)

    mu =  pm.Deterministic('mu', alpha + beta1 * x_data + beta2 * x_data**2)
    y_obs = pm.Normal("y_obs", mu=mu, sigma=sigma, observed=y, dims="data")

    idata_quad = pm.sample(1000, chains = 4, idata_kwargs={"log_likelihood":True})

pm.sample_posterior_predictive(idata_quad, model=quad_model, extend_inferencedata=True)

#plot mean
posterior = az.extract(idata_quad, num_samples=len(x))
x_plot = xr.DataArray(x)

mean_line = posterior["alpha"].mean() + posterior["beta1"].mean() * x_plot + posterior["beta2"].mean() * (x_plot**2)

plt.scatter(x, y)
plt.plot(x_plot, mean_line, c="C1")
plt.xlabel('X', fontsize = 14)
plt.ylabel('Y', fontsize = 14)
plt.title('Quadratic', fontsize = 14)


plt.savefig("q.png", bbox_inches='tight')
files.download("q.png")

"""Compare the Models"""

cmp_df = az.compare({"linear": idata_linear, "quadratic": idata_quad})
cmp_df

"""Averaging"""

avg_preds = az.weight_predictions([idata_quad, idata_linear], weights=cmp_df["weight"].values)

"""Plotting Results"""

_, ax = plt.subplots(figsize=(10, 6))
az.plot_kde(
    idata_linear.posterior_predictive["y_obs"].values,
    plot_kwargs={"color": "C0", "lw": 3},
    label="linear",
    ax=ax,
)
az.plot_kde(
    idata_quad.posterior_predictive["y_obs"].values,
    plot_kwargs={"color": "C1", "lw": 3},
    label="quadratic",
    ax=ax,
)
az.plot_kde(
    avg_preds.posterior_predictive["y_obs"].values,
    plot_kwargs={"color": "C2", "lw": 3, "ls": "--"},
    label="weighted",
    ax=ax,
)


plt.savefig("avg.png", bbox_inches='tight')
files.download("avg.png")

"""We can also change the weights

"""

avg_preds = az.weight_predictions([idata_linear, idata_quad], weights=[0.5, 0.5])

_, ax = plt.subplots(figsize=(10, 6))
az.plot_kde(
    idata_linear.posterior_predictive["y_obs"].values,
    plot_kwargs={"color": "C0", "lw": 3},
    label="linear",
    ax=ax,
)
az.plot_kde(
    idata_quad.posterior_predictive["y_obs"].values,
    plot_kwargs={"color": "C1", "lw": 3},
    label="quadratic",
    ax=ax,
)
az.plot_kde(
    avg_preds.posterior_predictive["y_obs"].values,
    plot_kwargs={"color": "C2", "lw": 3, "ls": "--"},
    label="weighted",
    ax=ax,
)


plt.savefig("avg2.png", bbox_inches='tight')
files.download("avg2.png")